{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功读取文件: global_dataset_state_dict_279.pt\n",
      "------------------------------\n",
      "数据类型: <class 'dict'>\n",
      "------------------------------\n",
      "字典中的键 (Keys):\n",
      "sample_offset\n",
      "epoch_id\n",
      "sample_index\n",
      "metadata\n",
      "------------------------------\n",
      "第一个键 'sample_offset' 对应的值的类型是: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义你要读取的文件名\n",
    "file_path = 'global_dataset_state_dict_279.pt'\n",
    "\n",
    "try:\n",
    "    # 使用 torch.load() 函数加载文件\n",
    "    # map_location='cpu' 参数是很有用的，特别是当你加载一个在 GPU 上训练和保存的模型，\n",
    "    # 但你当前的环境可能没有 GPU。这能确保模型权重被加载到 CPU 内存中，避免出错。\n",
    "    state_dict = torch.load(file_path, map_location='cpu')\n",
    "\n",
    "    print(f\"成功读取文件: {file_path}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # state_dict 是一个字典，你可以像操作普通 Python 字典一样操作它。\n",
    "    # 1. 打印 state_dict 的类型\n",
    "    print(f\"数据类型: {type(state_dict)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 2. 打印字典中所有的键 (keys)，这能让你了解文件中存储了哪些内容。\n",
    "    #    在模型文件中，键通常是模型层的名称（例如 'conv1.weight', 'fc2.bias'）。\n",
    "    print(\"字典中的键 (Keys):\")\n",
    "    for key in state_dict.keys():\n",
    "        print(key)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 3. 检查某个特定键对应的值的形状 (shape)\n",
    "    #    随机选择一个键来查看，或者选择一个你感兴趣的键。\n",
    "    if state_dict:\n",
    "        first_key = list(state_dict.keys())[0]\n",
    "        first_value = state_dict[first_key]\n",
    "        # 检查值的类型，通常是 torch.Tensor\n",
    "        print(f\"第一个键 '{first_key}' 对应的值的类型是: {type(first_value)}\")\n",
    "        # 打印张量的形状\n",
    "        if isinstance(first_value, torch.Tensor):\n",
    "            print(f\"第一个键 '{first_key}' 对应张量的形状是: {first_value.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 文件 '{file_path}' 未找到。请确保文件路径正确。\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_offset': 1159, 'epoch_id': 9, 'sample_index': 547328, 'metadata': {}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PYTHONPATH=/root/Megatron-LM python tools/convert_torch_dist_to_hf.py \\\n",
    "  --input-dir /apdcephfs/private_ethangeng/Qwen3-4B_slime/iter_0000499/ \\\n",
    "  --output-dir /apdcephfs/private_ethangeng/Qwen3-4B_slime_hf/iter_0000499/ \\\n",
    "  --vocab-size 151936\\\n",
    "  --origin-hf-dir /root/Qwen3-4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"北京。这个说法正确吗？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么\"\n",
    "b = \"北京。这个说法正确吗？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么？为什么\"\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 5209, 2182, 279, 4226, 2878, 1124, 79075, 46391, 151645, 198, 151644, 872, 198, 44, 13331, 374, 5779, 1635, 9014, 1091, 13658, 13, 62040, 273, 374, 220, 18, 14, 19, 438, 2310, 438, 13658, 13, 3555, 594, 279, 2790, 315, 862, 16639, 220, 16, 15, 1635, 504, 1431, 1416, 13658, 374, 220, 17, 15, 1635, 2310, 1431, 30, 151645, 198, 151644, 77091, 198, 151667, 198, 32313, 11, 1077, 594, 1490, 13, 2055, 279, 3491, 2727, 386, 13331, 374, 5779, 1635, 9014, 1091, 13658, 13, 1597, 1431, 13658, 374, 220, 17, 15, 13, 5005, 582, 1184, 311, 1477, 279, 2790, 315, 862, 16639, 220, 16, 15, 1635, 504, 1431, 13, 88190, 13, 6771, 752, 1438, 419, 1495, 3019, 553, 3019, 382, 5338, 11, 358, 1184, 311, 7071, 700, 862, 1482, 16639, 13, 13658, 374, 220, 17, 15, 1431, 13, 8704, 386, 13331, 374, 5779, 1635, 9014, 1091, 13658, 11, 429, 3363, 386, 13331, 594, 1482, 4231, 374, 220, 17, 15, 488, 220, 16, 15]]\n",
    "b = [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 5209, 2182, 279, 4226, 2878, 1124, 79075, 46391, 151645, 198, 151644, 872, 198, 44, 13331, 374, 5779, 1635, 9014, 1091, 13658, 13, 62040, 273, 374, 220, 18, 14, 19, 438, 2310, 438, 13658, 13, 3555, 594, 279, 2790, 315, 862, 16639, 220, 16, 15, 1635, 504, 1431, 1416, 13658, 374, 220, 17, 15, 1635, 2310, 1431, 30, 151645, 198, 151644, 77091, 198, 151667, 198, 32313, 11, 1077, 594, 1490, 13, 2055, 11, 279, 3491, 374, 911, 47209, 700, 279, 2790, 315, 862, 16639, 220, 16, 15, 1635, 504, 1431, 13, 88190, 13, 6771, 594, 1191, 553, 14719, 1495, 279, 1995, 2661, 382, 5338, 11, 386, 13331, 374, 5779, 1635, 9014, 1091, 13658, 13, 1597, 13658, 374, 5023, 220, 17, 15, 1635, 2310, 13, 2055, 11, 386, 13331, 594, 1482, 4231, 1035, 387, 4231, 315, 13658, 5519, 5779, 13, 2938, 1035, 387, 220, 17, 15, 488, 220, 16, 15, 284, 220, 18, 15, 13, 2055, 11, 386, 13331, 374, 220, 18, 15, 1431]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibroker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
